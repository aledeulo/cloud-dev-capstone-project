version: 2.1

orbs:
  aws-eks: circleci/aws-eks@2.2.0
  kubernetes: circleci/kubernetes@1.3
  aws-cli: circleci/aws-cli@3.1

node_docker_image: &node_docker_image
  docker:
    - image: cimg/node:12.16
      user: root

python_cluster_docker_image: &python_cluster_docker_image
  docker:
    - image: cimg/python:3.10

commands:
  install_aws_cli:
    description: Configure aws cli to deploy resources
    steps:
      - run:
          name: install aws cli
          command: pip install awscli
  
  destroy-serverless-deployment:
    description: Destroy back-end cloudformation stacks given a workflow ID.    
    steps:
      - run:
          name: Destroy environments
          when: on_fail
          command: |
               aws s3 rm s3://my-bucket-todo-images-${ENV} --recursive 
               aws cloudformation delete-stack --stack-name cloud-backend-app-${ENV}
               aws cloudformation delete-stack --stack-name eksctl-${ENV}-cluster-cluster

jobs:
  build-backend:
    <<: *node_docker_image
    steps:
      - checkout
      - restore_cache:
          key: backend-build-{{ checksum "./backend/package.json" }}
      - run:
          name: Build back-end
          command: |
            cd ./backend && npm install
      - save_cache:
          paths: 
            - ./node_modules
          key: backend-build-{{ checksum "./backend/package.json" }}

  build-client:
    <<: *node_docker_image
    steps:
      - checkout
      - restore_cache:
          key: frontend-build-{{ checksum "./client/package.json" }}
      - run:
          name: Build front-end
          command: |
            cd ./client && npm install
      - save_cache:
          paths: 
            - ./node_modules
          key: frontend-build-{{ checksum "./client/package.json" }}

  build-and-push-client-image:
    environment:
      IMAGE_NAME: client-app
    docker:
      - image: circleci/buildpack-deps:stretch
    steps:
      - checkout
      - setup_remote_docker
      - run:
          name: Build Docker image
          command: |
            cd ./client &&\
            docker build -t $IMAGE_NAME:latest . --no-cache &&\
            docker build -t $IMAGE_NAME . && docker tag $IMAGE_NAME ${DOCKER_USER}/$IMAGE_NAME:latest &&\
            echo "${DOCKER_PASSWORD}" | docker login -u "${DOCKER_USER}" --password-stdin &&\
            docker push ${DOCKER_USER}/$IMAGE_NAME
  
  deploy-serverless-backend:
    <<: *node_docker_image
    steps:
      - checkout
      - restore_cache:
          key: backend-build-{{ checksum "./backend/package.json" }}
      - run:
          name: Install serverless
          command: npm install -g serverless@2.21.1      
      - run:
          name: Update env vars in serverless.yml
          command: |
            cd ./backend &&\
            cat serverless_temp.yml |\
            sed "s|ENV_NAME|${ENV}|\
            g;s|AWS_REGION|${AWS_DEFAULT_REGION}|g" > serverless.yml
      - run:
          name: Install serverless plugins
          command: |
            cd ./backend &&\
            npm install serverless-webpack &&\
            npm install serverless-aws-documentation &&\
            npm install serverless-iam-roles-per-function &&\
            npm install serverless-plugin-tracing &&\
            npm install serverless-reqvalidator-plugin
      - run: 
          name: Configure serverless 
          command: |
            cd ./backend &&\
            sls config credentials --provider aws --key ${AWS_ACCESS_KEY_ID} --secret ${AWS_SECRET_ACCESS_KEY}
      - run:
          name: Deploy backend
          command: cd ./backend && serverless deploy --aws-region ${AWS_DEFAULT_REGION}

  create-aws-eks:
    <<: *python_cluster_docker_image
    steps:
      - checkout
      - install_aws_cli
      - run:
          name: check if the cluster exist
          command: |
            export VALIDATE=$(aws eks describe-cluster --name ${ENV}-cluster --query 'cluster.name')
            echo "$VALIDATE" > ~/validate
            if cat ~/validate | grep "${ENV}-cluster"
            then
                echo "Cluster ${ENV}-cluster already exist. Skipping job"
                circleci-agent step halt
                exit 0
            else
                echo "Attempting to create the cluster $ENV-cluster"
            fi
      - aws-eks/create-cluster:
          cluster-name: ${ENV}-cluster 
          aws-region: ${AWS_DEFAULT_REGION}
          nodegroup-name: ${ENV}-workers
          node-type: t3.medium
          nodes-min: 1
          nodes-max: 2

  deploy-to-eks:
    <<: *python_cluster_docker_image
    steps:
      - checkout
      - install_aws_cli
      - run:
          name: config namespace
          command: |
            cat ./client/deployment/namespace_tmpl.yml |\
              sed "s|ENV|${ENV}|g" > ./client/deployment/namespace.yml
      - run:
          name: config secrets
          command: |
            cat ./client/deployment/secrets_tmpl.yml |\
              sed "s|ENV|${ENV}|g" > ./client/deployment/secrets.yml
      - run:
          name: config deployment
          command: |
            # aws apigateway get-rest-apis --query 'items[?name==`${ENV}-cloud-backend-app`].id' --output text
            # export API_ID=$(aws apigateway get-rest-apis --query 'items[?name==`${ENV}-cloud-backend-app`].id' --output text)
            # echo 'API_ID: ' $API_ID
            cat ./client/deployment/deployment_tmpl.yml |\
              sed "s|ENV|${ENV}|\
              g;s|GATEWAY|${API_GATEWAY_ID}|\
              g;s|DOCKER_USER|${DOCKER_USER}|g" > ./client/deployment/deployment.yml
              cat ./client/deployment/deployment.yml
      - kubernetes/install-kubectl:
          kubectl-version: v1.23.5
      - aws-eks/update-kubeconfig-with-authenticator:
          cluster-name: ${ENV}-cluster
          install-kubectl: true
          aws-region: ${AWS_DEFAULT_REGION}
      - kubernetes/create-or-update-resource:
          resource-file-path: "./client/deployment/namespace.yml"
      - kubernetes/create-or-update-resource:
          resource-file-path: "./client/deployment/secrets.yml"
          namespace: ${ENV}
      - kubernetes/create-or-update-resource:
          get-rollout-status: true
          resource-file-path: "./client/deployment/deployment.yml"
          resource-name: deployment/client-app
          show-kubectl-command: true
          namespace: ${ENV}
      - kubernetes/create-or-update-resource:
          resource-file-path: "./client/deployment/service.yml"
          namespace: ${ENV}
      - run:
          name: get deployment status
          command:  kubectl get pods,deployments,svc -n ${ENV}


workflows:
  deployment-workflow:
    jobs:
      - create-aws-eks:
          filters:
            branches:
              only: [main, dev]
      - build-backend:
          filters:
            branches:
              only: [main, dev]
      - deploy-serverless-backend:
          requires: [build-backend]
      - build-client:
          filters:
            branches:
              only: [main, dev]      
      - build-and-push-client-image:
          requires: [build-client, deploy-serverless-backend]
      - deploy-to-eks:
          requires: [deploy-serverless-backend, build-and-push-client-image, create-aws-eks]
      

